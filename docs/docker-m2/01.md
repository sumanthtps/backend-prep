---
title: Docker Recap – From Legacy Deployment to Containerized Simplicity
sidebar_position: 1
---

## Introduction

Getting code to run consistently across machines is a **classic software
challenge**. Docker revolutionizes the way applications are built, shared, and
deployed by solving environment drift and dependency hell.

This recap breaks down the **evolution of deployment tools**, explains how
Docker works under the hood, and compares **containers vs virtual machines**.

---

## Legacy Deployment Challenges

Traditionally, deploying applications across environments was hard because:

- **Different operating systems** might have different libraries or versions.
- **Hardware dependencies** could vary.
- Configuration files and environment variables might differ.

### Example Problem

> You test your app on Ubuntu with Python 3.8, but production runs on CentOS
> with Python 3.6. Result? It crashes.

---

## Early Tools and Their Trade-offs

### Configuration Management Tools

Tools like:

- **Chef** (Ruby-based)
- **Ansible** (YAML + Python)
- **Puppet** (Ruby/C++)

They used the idea of "**infrastructure as code**" to provision and configure
environments.

#### Downsides:

- Steep learning curve (markup + language + tool)
- Required **pre-installed agents or interpreters** on target machines.
- Changes were often **imperative**, not easily reversible.

---

## Vagrant – Portable VMs

Vagrant by **HashiCorp** offered another step:

- Used **HCL (HashiCorp Configuration Language)**.
- Managed **prebuilt VMs**.
- Focused on **developer experience** with reproducible environments.

#### Limitations:

- VMs were **heavyweight**.
- Boot-up was **slow**.
- Still needed provisioning scripts to install tools (e.g., `apt`, `yum`).

---

## Docker – The Container Revolution

Docker took a **radically simpler** approach using:

- **Images** – Portable, immutable snapshots of your app.
- **Containers** – Lightweight, runtime instances of those images.

### Key Innovations

1. **Dockerfile** – Text file to define how to build an image.
2. **Docker Registry** – Store and share images (e.g., DockerHub).
3. **CLI + API** – Simplifies the container lifecycle.

```Dockerfile
# A basic example
FROM node:20
COPY . /app
WORKDIR /app
RUN npm install
CMD ["node", "index.js"]
```

This makes your app **self-contained**.

---

## Technical Foundations of Docker

Docker uses **Linux kernel features**:

### 1. Namespaces

- Provide **isolation**: each container thinks it has its own resources (e.g.,
  network, PID, filesystem).
- Examples:

  - `net` namespace → isolated IP stack.
  - `mnt` namespace → isolated mounts.

### 2. Control Groups (cgroups)

- Control **resource usage** (CPU, memory, disk I/O).
- Prevent a container from hogging all system resources.

### 3. Union File Systems (OverlayFS)

- Allow images to be **layered** and **cached** efficiently.
- A new container writes to a top read-write layer.

---

## Misconception: Containers are not Mini-VMs

### Virtual Machines

- Use a **hypervisor** (like VMware, VirtualBox, KVM).
- Emulate full hardware.
- Require a **guest OS** (full-blown OS with kernel, drivers).
- Run **multiple processes** like a real computer.

![VM vs Container](https://akfpartners.com//uploads/blog/VM_Image.PNG)

> VMs are like owning separate houses. Containers are like rooms in the same
> house with locked doors.

### Containers

- **Do not emulate hardware.**
- Share **host kernel**.
- Spin up **faster** and are **more lightweight**.
- Designed to run **a single process** per container (but workarounds like
  supervisord exist).

---

## Summary: Docker's Advantages

| Feature        | Virtual Machine            | Docker Container      |
| -------------- | -------------------------- | --------------------- |
| Boot Time      | Minutes                    | Seconds               |
| Resource Usage | Heavy (full OS)            | Light (shared OS)     |
| Isolation      | Strong (hardware-level)    | Medium (kernel-level) |
| Use Case       | Full environment emulation | App-level packaging   |
| Sharing        | Hard                       | Easy (DockerHub)      |
| Portability    | Lower (OS-dependent)       | Higher (image-based)  |

---

## Example Workflow

1. Developer writes a `Dockerfile`.
2. Builds an image with:

   ```bash
   docker build -t my-app .
   ```

3. Shares it to DockerHub or a private registry.
4. Runs a container on any machine:

   ```bash
   docker run -p 8080:8080 my-app
   ```

App runs **identically**, no matter the host OS (as long as it supports Docker).

---

## Advanced Topics (Coming Up Later)

- Multi-container apps with **Docker Compose**
- Network and volume management
- Docker security (capabilities, seccomp, AppArmor)
- Running multiple processes with **init systems**
- Image optimization (multi-stage builds)

---

## Questions and Answers

### Q1: What is the difference between Docker and Vagrant?

**A**: Vagrant uses virtual machines (full OS) with slower startup and higher
resource usage. Docker uses containers with shared host OS, faster startup, and
lower overhead.

---

### Q2: Can containers run on Windows or Mac?

**A**: Yes, but they run inside a lightweight **Linux VM** via WSL2 (on Windows)
or a hypervisor (on Mac) since containers depend on Linux kernel features.

---

### Q3: Are containers secure?

**A**: Containers **isolate** apps but share the host kernel. With proper
controls (namespaces, cgroups, seccomp, AppArmor), they are secure **enough**
for most use cases. For stronger isolation, consider Kata Containers or gVisor.

---

### Q4: Why only one app per container?

**A**: It enforces **single-responsibility**. Easier to monitor, log, restart,
and scale. You can still run multiple apps with a supervisor process or use
Docker Compose to group containers.

---

### Q5: What happens when a container stops?

**A**: The container process terminates and disappears unless:

- It's restarted (`--restart always`)
- Logs are preserved externally
- Volumes are mounted to retain data

---
