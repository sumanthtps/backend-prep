---
sidebar_position: 24
---

# Top Interview Queries
These are **real-world PostgreSQL interview questions** that cover **SQL queries, performance tuning, indexing, transactions, replication, JSON, and advanced PostgreSQL features**.  

---

## **1️⃣ Basic SQL Queries**  
1️⃣ **Get all users whose name starts with 'A'**  
```sql
SELECT * FROM users WHERE name LIKE 'A%';
```

2️⃣ **Find the second-highest salary from an `employees` table**  
```sql
SELECT DISTINCT salary 
FROM employees 
ORDER BY salary DESC 
LIMIT 1 OFFSET 1;
```

3️⃣ **Find duplicate email addresses in a `users` table**  
```sql
SELECT email, COUNT(*) 
FROM users 
GROUP BY email 
HAVING COUNT(*) > 1;
```

4️⃣ **Delete duplicate rows while keeping the first occurrence**  
```sql
DELETE FROM users 
WHERE id NOT IN (
    SELECT MIN(id) FROM users GROUP BY email
);
```

5️⃣ **Find the nth highest salary using a subquery**  
```sql
SELECT DISTINCT salary 
FROM employees e1 
WHERE 3 = (SELECT COUNT(DISTINCT salary) FROM employees e2 WHERE e2.salary >= e1.salary);
```

---

## **2️⃣ Joins & Aggregations**  
6️⃣ **Find users who have placed orders (INNER JOIN)**  
```sql
SELECT users.name, orders.amount 
FROM users 
INNER JOIN orders ON users.id = orders.user_id;
```

7️⃣ **Find users who have never placed orders (LEFT JOIN with NULL check)**  
```sql
SELECT users.name 
FROM users 
LEFT JOIN orders ON users.id = orders.user_id 
WHERE orders.id IS NULL;
```

8️⃣ **Find total revenue per user (JOIN + GROUP BY)**  
```sql
SELECT users.name, SUM(orders.amount) AS total_spent 
FROM users 
JOIN orders ON users.id = orders.user_id 
GROUP BY users.name;
```

9️⃣ **Find the department with the highest average salary**  
```sql
SELECT department_id, AVG(salary) AS avg_salary 
FROM employees 
GROUP BY department_id 
ORDER BY avg_salary DESC 
LIMIT 1;
```

🔟 **Find the top 3 customers based on total order amount**  
```sql
SELECT user_id, SUM(amount) AS total_spent 
FROM orders 
GROUP BY user_id 
ORDER BY total_spent DESC 
LIMIT 3;
```

---

## **3️⃣ Window Functions**  
1️⃣1️⃣ **Find the running total of orders for each customer**  
```sql
SELECT user_id, amount, 
       SUM(amount) OVER (PARTITION BY user_id ORDER BY order_date) AS running_total 
FROM orders;
```

1️⃣2️⃣ **Rank employees by salary within each department**  
```sql
SELECT name, department_id, salary, 
       RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) AS rank 
FROM employees;
```

1️⃣3️⃣ **Find the previous order amount for each order (LAG function)**  
```sql
SELECT user_id, order_id, amount, 
       LAG(amount) OVER (PARTITION BY user_id ORDER BY order_date) AS prev_order_amount 
FROM orders;
```

1️⃣4️⃣ **Find the highest salary per department using `MAX()` window function**  
```sql
SELECT name, department_id, salary, 
       MAX(salary) OVER (PARTITION BY department_id) AS max_salary 
FROM employees;
```

1️⃣5️⃣ **Get cumulative order count per customer**  
```sql
SELECT user_id, order_id, 
       COUNT(*) OVER (PARTITION BY user_id ORDER BY order_date) AS cumulative_count 
FROM orders;
```

---

## **4️⃣ Indexing & Performance Optimization**  
1️⃣6️⃣ **Check if a query is using an index**  
```sql
EXPLAIN ANALYZE SELECT * FROM users WHERE email = 'test@example.com';
```

1️⃣7️⃣ **Create an index on an email column**  
```sql
CREATE INDEX idx_users_email ON users(email);
```

1️⃣8️⃣ **Check index usage in a database**  
```sql
SELECT relname, indexrelname 
FROM pg_stat_user_indexes;
```

1️⃣9️⃣ **Use `GIN` index for Full-Text Search**  
```sql
CREATE INDEX idx_users_search ON users USING GIN(to_tsvector('english', name));
```

2️⃣0️⃣ **Use a partial index for active users only**  
```sql
CREATE INDEX idx_active_users ON users(email) WHERE is_active = true;
```

---

## **5️⃣ JSON & JSONB Queries**  
2️⃣1️⃣ **Find users whose details contain a specific city**  
```sql
SELECT * FROM users WHERE details @> '{"city": "New York"}';
```

2️⃣2️⃣ **Extract the name field from a JSONB column**  
```sql
SELECT details->>'name' FROM users;
```

2️⃣3️⃣ **Update a JSONB field in PostgreSQL**  
```sql
UPDATE users 
SET details = jsonb_set(details, '{city}', '"Los Angeles"') 
WHERE id = 1;
```

2️⃣4️⃣ **Check if a JSON field contains a key**  
```sql
SELECT * FROM users WHERE details ? 'skills';
```

2️⃣5️⃣ **Find users with at least one skill from a given list**  
```sql
SELECT * FROM users WHERE details->'skills' ?| ARRAY['SQL', 'Python'];
```

---

## **6️⃣ Transactions & Concurrency Control**  
2️⃣6️⃣ **Start a transaction and roll it back**  
```sql
BEGIN;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
ROLLBACK;
```

2️⃣7️⃣ **Use Savepoints to handle partial rollbacks**  
```sql
SAVEPOINT sp1;
UPDATE accounts SET balance = balance - 50 WHERE id = 1;
ROLLBACK TO sp1;
```

2️⃣8️⃣ **Check current transactions**  
```sql
SELECT * FROM pg_stat_activity WHERE state = 'active';
```

2️⃣9️⃣ **Kill a long-running query**  
```sql
SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE state = 'active';
```

3️⃣0️⃣ **Check deadlocks**  
```sql
SELECT * FROM pg_locks WHERE granted = false;
```

---

## **7️⃣ Replication & High Availability**  
3️⃣1️⃣ **Enable Logical Replication**  
```conf
wal_level = logical
max_replication_slots = 5
```

3️⃣2️⃣ **Create a Logical Replication Slot**  
```sql
SELECT * FROM pg_create_logical_replication_slot('my_slot', 'test_decoding');
```

3️⃣3️⃣ **Start Streaming Changes from the WAL**  
```sql
SELECT * FROM pg_logical_slot_get_changes('my_slot', NULL, NULL);
```

3️⃣4️⃣ **Set up Point-in-Time Recovery (PITR)**  
```conf
archive_mode = on
archive_command = 'cp %p /var/lib/postgresql/wal_archive/%f'
recovery_target_time = '2025-03-01 10:30:00'
```

3️⃣5️⃣ **Promote a Standby Server to Primary**  
```sh
pg_ctl -D /var/lib/postgresql/data promote
```

---

## **8️⃣ Query Performance Optimization**
3️⃣6️⃣ **Check slow queries**  
```sql
SELECT query, total_time FROM pg_stat_statements ORDER BY total_time DESC LIMIT 5;
```

3️⃣7️⃣ **Run Vacuum to clean up dead tuples**  
```sql
VACUUM ANALYZE;
```

3️⃣8️⃣ **Enable Parallel Query Execution**  
```sql
SET max_parallel_workers_per_gather = 4;
```

3️⃣9️⃣ **Enable Connection Pooling with PgBouncer**  
```sh
pgbouncer -d /etc/pgbouncer/pgbouncer.ini
```

4️⃣0️⃣ **Use `EXPLAIN ANALYZE` to Debug Queries**  
```sql
EXPLAIN ANALYZE SELECT * FROM orders WHERE amount > 1000;
```

🔥 **Want More? Let me know if you need in-depth explanations for any query! 🚀**