---
sidebar_position: 20
---

# Logical Decoding & Change Data Capture (CDC)

Logical Decoding allows PostgreSQL to **stream real-time database changes**
(INSERT, UPDATE, DELETE) to external systems like **Kafka, RabbitMQ, or another
database**. This is useful for **Change Data Capture (CDC), replication, and
event-driven architectures**.

---

## **1Ô∏è‚É£ What is Logical Decoding?**

‚úî **Extracts database changes (DML operations) in real-time** from the WAL
(Write-Ahead Log).  
‚úî **Streams data to external consumers** instead of applying changes to another
PostgreSQL instance.  
‚úî Enables **CDC (Change Data Capture)** for **real-time event-driven systems**.

üöÄ **Use Cases:**

- **Streaming changes to Kafka or RabbitMQ for microservices**.
- **Syncing PostgreSQL with Elasticsearch** for search indexing.
- **Real-time replication between databases** (cross-version PostgreSQL
  replication).

---

## **2Ô∏è‚É£ Enabling Logical Decoding in PostgreSQL**

Logical decoding is **disabled by default** and requires configuration changes.

‚úÖ **Step 1: Enable Logical Replication in `postgresql.conf`**

```conf
wal_level = logical
max_replication_slots = 5
max_wal_senders = 5
```

‚úî **Restart PostgreSQL for changes to take effect**

```sh
systemctl restart postgresql
```

‚úÖ **Step 2: Create a Replication Slot for Logical Decoding**

```sql
SELECT * FROM pg_create_logical_replication_slot('my_slot', 'test_decoding');
```

‚úî **Creates a slot named `my_slot` to track changes**.

‚úÖ **Step 3: Start Streaming Changes**

```sql
SELECT * FROM pg_logical_slot_get_changes('my_slot', NULL, NULL);
```

‚úî **Returns database changes from the WAL in a readable format!**

---

## **3Ô∏è‚É£ Streaming Changes Using `wal2json` Plugin**

‚úî **Converts WAL changes into JSON format** (easier for external consumers).

‚úÖ **Step 1: Install `wal2json` Extension**

```sh
apt install postgresql-contrib
```

‚úÖ **Step 2: Create a Replication Slot with `wal2json`**

```sql
SELECT * FROM pg_create_logical_replication_slot('json_slot', 'wal2json');
```

‚úÖ **Step 3: Fetch Changes in JSON Format**

```sql
SELECT data FROM pg_logical_slot_get_changes('json_slot', NULL, NULL);
```

üöÄ **Now, PostgreSQL changes are output as JSON!**

---

## **4Ô∏è‚É£ Using Logical Replication for Table-Level CDC**

‚úî Unlike physical replication, **logical replication allows selective table
replication**.

‚úÖ **Step 1: Create a Publication on the Primary Database**

```sql
CREATE PUBLICATION my_pub FOR TABLE users, orders;
```

üöÄ **Now, `users` and `orders` tables will be replicated!**

‚úÖ **Step 2: Create a Subscription on the Replica Database**

```sql
CREATE SUBSCRIPTION my_sub CONNECTION 'host=primary_host dbname=mydb user=replica_user'
PUBLICATION my_pub;
```

‚úî **Now, changes from `users` and `orders` will sync in real-time!**

---

## **5Ô∏è‚É£ Streaming PostgreSQL Changes to Kafka**

‚úî **PostgreSQL CDC + Kafka enables event-driven microservices**.  
‚úî **Debezium + Kafka Connect can capture changes from PostgreSQL.**

‚úÖ **Step 1: Install Debezium PostgreSQL Connector**

```sh
confluent-hub install debezium/debezium-connector-postgresql:latest
```

‚úÖ **Step 2: Configure Debezium Connector** (`config.json`)

```json
{
  "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
  "database.hostname": "localhost",
  "database.port": "5432",
  "database.user": "postgres",
  "database.password": "password",
  "database.dbname": "mydb",
  "database.server.name": "pg_server",
  "slot.name": "debezium_slot"
}
```

‚úÖ **Step 3: Start Kafka Connect with Debezium**

```sh
curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" \
  http://localhost:8083/connectors/ -d @config.json
```

üöÄ **Now, PostgreSQL changes are streamed to Kafka topics!**

---

## **üìù Quiz - Logical Decoding & Change Data Capture**

1Ô∏è‚É£ What is the purpose of **Logical Decoding** in PostgreSQL?  
2Ô∏è‚É£ How do you enable Logical Replication in PostgreSQL?  
3Ô∏è‚É£ What does the `wal2json` plugin do?  
4Ô∏è‚É£ How do you create a replication slot for Logical Decoding?  
5Ô∏è‚É£ How can PostgreSQL stream changes to Kafka?

Here are the correct answers:

1Ô∏è‚É£ **What is the purpose of Logical Decoding in PostgreSQL?**  
‚úî Logical Decoding **streams real-time database changes (INSERT, UPDATE, DELETE)
to external systems**.  
‚úî Used for **Change Data Capture (CDC)**, **replication**, and **event-driven
architectures**.

‚úÖ **Example Query to Stream Changes:**

```sql
SELECT * FROM pg_logical_slot_get_changes('my_slot', NULL, NULL);
```

üöÄ **Returns a list of database changes!**

---

2Ô∏è‚É£ **How do you enable Logical Replication in PostgreSQL?**  
‚úî **Modify `postgresql.conf` to enable logical replication:**

```conf
wal_level = logical
max_replication_slots = 5
max_wal_senders = 5
```

‚úî **Restart PostgreSQL:**

```sh
systemctl restart postgresql
```

üöÄ **Now, logical replication is enabled!**

---

3Ô∏è‚É£ **What does the `wal2json` plugin do?**  
‚úî **Converts Write-Ahead Log (WAL) changes into JSON format**, making it easier
for external consumers like **Kafka, RabbitMQ, or Elasticsearch**.

‚úÖ **Example Query Using `wal2json`:**

```sql
SELECT data FROM pg_logical_slot_get_changes('json_slot', NULL, NULL);
```

üöÄ **Streams PostgreSQL changes as JSON output!**

---

4Ô∏è‚É£ **How do you create a replication slot for Logical Decoding?**  
‚úî **Use `pg_create_logical_replication_slot()` to create a slot:**

```sql
SELECT * FROM pg_create_logical_replication_slot('my_slot', 'test_decoding');
```

‚úî **Keeps track of changes in the WAL log for logical decoding.**

---

5Ô∏è‚É£ **How can PostgreSQL stream changes to Kafka?**  
‚úî **Use Debezium (Kafka Connect) to capture PostgreSQL changes and send them to
Kafka.**

‚úÖ **Step 1: Install Debezium Connector for PostgreSQL:**

```sh
confluent-hub install debezium/debezium-connector-postgresql:latest
```

‚úÖ **Step 2: Configure Debezium (`config.json`)**

```json
{
  "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
  "database.hostname": "localhost",
  "database.port": "5432",
  "database.user": "postgres",
  "database.password": "password",
  "database.dbname": "mydb",
  "database.server.name": "pg_server",
  "slot.name": "debezium_slot"
}
```

‚úÖ **Step 3: Start Kafka Connect with Debezium:**

```sh
curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" \
  http://localhost:8083/connectors/ -d @config.json
```

üöÄ **Now, PostgreSQL changes are streamed to Kafka topics!**

üî• **Score: 5/5 if you got all correct!** üéØ

---

### **Next Topic: PostgreSQL in Microservices & Cloud** üöÄ

We‚Äôll cover **PostgreSQL best practices in Docker, Kubernetes, AWS RDS,
multi-tenant databases, and connection pooling for high scalability**.
